# [Paper Title]


## Running the code

Create an environment (e.g., using `pip` or `conda`) and install the packages specified in `requirements.txt`.

To train the models run,
```
python -m nav_to_center run quick_test -j4
```
where `quick_test` is the config-generating function in `nav_to_center/experiment_configs.py` and `-j4` specifies the number of experiments to run in parallel (use `-j$(nproc)` for best performance and `-j1` for debugging).
`quick_test` is a toy configuration that should run quickly; it takes 1.5 minutes with `-j4` on a laptop with an Intel i7-4600U.
You can run TensorBoard in `log/` or `log/quick_test/` to track training progress.

After training the models, you must generate the evaluation data with those trained models.
```
python -m nav_to_center eval log/quick_test -j4
```
where `log/temperature` contains the trained models generated by the previous step.
This takes about 2 minutes on the aforementioned laptop.

Finally run the analysis using,
```
python -m nav_to_center analyze quick_test
```
where `quick_test` is the name of analysis given in `nav_to_center/analysis_configs.py`.
The results of the linear regression analysis will be printed to the screen; the figures will be saved under `results/quick_test/` as specified in `analysis_config.py`.


## Experiments used in the paper

We use the following analyses in the paper:
- `corr_sparsity` - correlation between reward sparsity and entropy;
  data generated using `config/sparsity.py`
- `corr_temp` - correlation between bottleneck temperature and entropy;
  data generated using `config/temperature.py`
- `corr_lr` - correlation between learning rate and entropy;
  data generated using `config/learning_rate.py`
- `corr_lexicon_size` - correlation between lexicon size and entropy;
  data generated using `config/lexicon_size.py`

